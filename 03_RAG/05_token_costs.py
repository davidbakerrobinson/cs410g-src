from langchain_google_genai import GoogleGenerativeAI
import readline

def calculate_completion_cost(query):
    # Cost per million tokens (6/2024)
    GEMINI_15_INPUT = 3.5
    GEMINI_15_OUTPUT = 10.5

    # Cost per token
    per_token_input_cost=GEMINI_15_INPUT/1000000
    per_token_output_cost=GEMINI_15_OUTPUT/1000000

    llm=GoogleGenerativeAI(model="gemini-1.5-pro")

    prompt_tokens = llm.get_num_tokens(query)
    response = llm.invoke(query)
    output_tokens = llm.get_num_tokens(response)
    total_cost= prompt_tokens * per_token_input_cost + output_tokens * per_token_output_cost
    print(f"-----Output response-----\n {response}")
    print(f"-----Token estimation and cost calculation-----")
    print(f"The number of input tokens: {prompt_tokens} and the number of output tokens: {output_tokens}")
    print(f"The rate for input tokens: {per_token_input_cost}/token and the rate for output tokens: {per_token_output_cost}/token")
    print(f"Total cost is: {total_cost}")

print("Enter a text query and see how much it will cost based on the number of input")
print("tokens in the query and the number of output tokens generated by the model")
while True:
    line = input(">> ")
    if line:
        calculate_completion_cost(line)
    else:
        break
